{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First learning attempts\n",
    "### using Beethoven dataset\n",
    "* 29 pieces + transpositions across 2 octaves\n",
    "* ~70h of music (2.7h per transposition)\n",
    "* 0.025s resolution (40fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_NOTE_VELOCITY = True\n",
    "\n",
    "# loading data files names\n",
    "import os\n",
    "\n",
    "path = '.\\\\datasets\\\\beethoven\\\\'\n",
    "file_names = os.listdir(path)\n",
    "file_names = list(filter(lambda fn: '.npz' in fn or '.npy' in fn or '.csv' in fn, file_names))\n",
    "assert len(file_names) > 0, 'Data not found'\n",
    "\n",
    "f'Found {len(file_names)} files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data files\n",
    "from midi_numpy.common import read_numpy_midi\n",
    "file_paths = [f'{path}{fn}' for fn in file_names]\n",
    "\n",
    "from random import choice\n",
    "def load_tracks(n):\n",
    "    print('loading tracks')\n",
    "    sampled_file_paths = [choice(file_paths) for _ in range(n)]\n",
    "    tracks = [read_numpy_midi(fp) for fp in sampled_file_paths]\n",
    "    if IGNORE_NOTE_VELOCITY:\n",
    "        tracks = [t[:, :128] for t in tracks]\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select batch\n",
    "def create_batch(data, batch_size, seq_length):\n",
    "    # each sequence is from diffrent track\n",
    "    tracks_indices = np.random.randint(0, len(data), batch_size)\n",
    "    seq_indicies = [np.random.randint(0, len(data[ti]) - seq_length - 1) for ti in tracks_indices]\n",
    "    # select sequences from selected tracks\n",
    "    # data form is many-to-one\n",
    "    x = np.stack([data[ti][si:si + seq_length] for ti,si in zip(tracks_indices, seq_indicies)])\n",
    "    y = np.stack([data[ti][si + seq_length] for ti,si in zip(tracks_indices, seq_indicies)])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset generator\n",
    "import numpy as np\n",
    "def data_gen(batch_size, seq_len=(1, 400), track_count=25):\n",
    "    # x data shape should be [batch_size, sequence_len, input_dim]\n",
    "    # y shape is [batch_size, input_dim]  \n",
    "    while True:\n",
    "        print('reloading data')\n",
    "        data = load_tracks(track_count)  \n",
    "        print(f'reloaded data')\n",
    "        for _ in range(1000 * len(data)):\n",
    "            seq = np.random.randint(seq_len[0], seq_len[1])\n",
    "            yield create_batch(data, batch_size, seq)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "INPUT_SIZE = 128 if IGNORE_NOTE_VELOCITY else 256\n",
    "HIDDEN_SIZE = 512\n",
    "OUTPUT_SIZE = INPUT_SIZE\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "INPUT_SHAPE = (None, INPUT_SIZE)\n",
    "# could be INPUT_SHAPE = (SEQUENCE_LENGTH, INPUT_SIZE)\n",
    "# however predicting would have to have same seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(HIDDEN_SIZE, input_shape=INPUT_SHAPE),\n",
    "    keras.layers.Dense(OUTPUT_SIZE, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='mean_squared_error', \n",
    "    optimizer='adam', \n",
    "    metrics=['binary_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or load saved model\n",
    "base_path = ''\n",
    "file_name = 'beth_notransp_randchunk_bcr_512_22epochs_90.0m.h5'\n",
    "model = keras.models.load_model(base_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre running operations\n",
    "# some stat data accumultors for re-running model\n",
    "from time import time\n",
    "epochs_elapsed = 0\n",
    "minutes_elapsed = 0\n",
    "gen = data_gen(BATCH_SIZE)\n",
    "test_gen = data_gen(BATCH_SIZE, track_count=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "STEPS_PER_EPOCH = 1000\n",
    "start_time = time()\n",
    "\n",
    "model.fit_generator(\n",
    "    gen, \n",
    "    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "    epochs=EPOCHS, \n",
    "    validation_data=test_gen, \n",
    "    validation_steps=100\n",
    ")\n",
    "\n",
    "minutes_elapsed += (time() - start_time) // 60\n",
    "epochs_elapsed += EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = ''\n",
    "keywords = '_'.join(['beth', 'notransp', 'randchunk'])\n",
    "file_name = f'{keywords}_{HIDDEN_SIZE}_{epochs_elapsed}epochs_{minutes_elapsed}m.h5'\n",
    "\n",
    "keras.models.save_model(model, base_path + file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
