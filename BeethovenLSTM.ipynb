{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First learning attempts\n",
    "### using Beethoven dataset\n",
    "* 29 pieces + transpositions across 2 octaves\n",
    "* ~70h of music (2.7h per transposition)\n",
    "* 0.025s resolution (40fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_NOTE_VELOCITY = True\n",
    "TARGET_IS_SEQUENCE = True\n",
    "MAX_WINDOW_SIZE = 100\n",
    "\n",
    "# loading data files names\n",
    "import os\n",
    "\n",
    "path = '/content/drive/My Drive/datasets/beethoven100ms/transposed/'\n",
    "file_names = os.listdir(path)\n",
    "file_names = list(filter(lambda fn: '.npz' in fn or '.npy' in fn or '.csv' in fn, file_names))\n",
    "assert len(file_names) > 0, 'Data not found'\n",
    "\n",
    "f'Found {len(file_names)} files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data files\n",
    "def read_numpy_midi(input_path):\n",
    "    import numpy as np\n",
    "    from scipy import sparse\n",
    "    if 'csv' in input_path:\n",
    "        return np.loadtxt(input_path, delimiter=\",\", dtype=np.int32)\n",
    "    elif 'npy' in input_path:\n",
    "        return np.load(input_path).astype(np.float32)\n",
    "    elif 'npz' in input_path:\n",
    "        sparse_numpy = sparse.load_npz(input_path)\n",
    "        return sparse_numpy.toarray().astype(np.float32)\n",
    "\n",
    "file_paths = [f'{path}{fn}' for fn in file_names]\n",
    "\n",
    "from random import choice\n",
    "def load_tracks(n):\n",
    "    print('loading tracks')\n",
    "    sampled_file_paths = [choice(file_paths) for _ in range(n)]\n",
    "    tracks = [read_numpy_midi(fp) for fp in sampled_file_paths]\n",
    "    if IGNORE_NOTE_VELOCITY:\n",
    "        tracks = [t[:, :128] for t in tracks]\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select batch\n",
    "def create_batch(data, batch_size, seq_length):\n",
    "    # each sequence is from diffrent track\n",
    "    tracks_indices = np.random.randint(0, len(data), batch_size)\n",
    "    # select sequences from selected tracks\n",
    "    seq_indicies = [np.random.randint(0, len(data[ti]) - seq_length - 1) \n",
    "                    for ti in tracks_indices]\n",
    "    # transform indices to slices\n",
    "    x_slice = lambda si: np.s_[si:si + seq_length]\n",
    "    y_slice = lambda si: (\n",
    "        np.s_[si + 1:si + seq_length + 1] \n",
    "        if TARGET_IS_SEQUENCE \n",
    "        else np.s_[si + seq_length]\n",
    "    )\n",
    "    x = np.stack([data[ti][x_slice(si)] for ti,si in zip(tracks_indices, seq_indicies)])\n",
    "    y = np.stack([data[ti][y_slice(si)] for ti,si in zip(tracks_indices, seq_indicies)])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset generator\n",
    "import numpy as np\n",
    "def data_gen(batch_size, seq_len, track_count=25):\n",
    "    # x data shape should be [batch_size, sequence_len, input_dim]\n",
    "    # y shape is [batch_size, input_dim]  \n",
    "    while True:\n",
    "        print('reloading data')\n",
    "        data = load_tracks(track_count)  \n",
    "        print(f'reloaded data')\n",
    "        for _ in range(1000 * len(data)):\n",
    "            seq = np.random.randint(seq_len[0], seq_len[1])\n",
    "            yield create_batch(data, batch_size, seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as K\n",
    "\n",
    "INPUT_SIZE = 128 if IGNORE_NOTE_VELOCITY else 256\n",
    "HIDDEN_SIZE = 512\n",
    "OUTPUT_SIZE = INPUT_SIZE\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "INPUT_SHAPE = (None, INPUT_SIZE)\n",
    "# None means that sequence length is not strictly defined\n",
    "# 3 dim - batch size, is defined implicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PenalizeFalseNegatives(penalty_factor, lossF):\n",
    "    def inner(y_true, y_pred):\n",
    "        res = lossF(y_true, y_pred)\n",
    "        # boolean tensor indicating false negatives \n",
    "        # if y_true == 1 and y_pred == 0\n",
    "        FN = K.backend.clip(y_true - K.backend.round(y_pred), 0, 1)\n",
    "        # count false negatives\n",
    "        FN = K.backend.sum(FN)\n",
    "        penalty = K.backend.pow(1. + penalty_factor, FN)\n",
    "        return res * penalty\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.00193"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([1,0,1])\n",
    "y_pred = np.array([0,0,0])\n",
    "l = PenalizeFalseNegatives(0.1, K.losses.BinaryCrossentropy())\n",
    "r = l(K.backend.variable(y_true), K.backend.variable(y_pred))\n",
    "K.backend.eval(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = K.models.Sequential([\n",
    "    K.layers.LSTM(\n",
    "        HIDDEN_SIZE, \n",
    "        input_shape=INPUT_SHAPE, \n",
    "        return_sequences=TARGET_IS_SEQUENCE\n",
    "    ),\n",
    "    K.layers.Dense(OUTPUT_SIZE, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "#     loss=PenalizeFalseNegatives(0.1, K.losses.BinaryCrossentropy()), \n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=K.optimizers.Adam(), \n",
    "    metrics=[\n",
    "        K.metrics.BinaryAccuracy(), \n",
    "        K.metrics.FalsePositives(), \n",
    "        K.metrics.FalseNegatives()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or load saved model\n",
    "base_path = '/content/drive/My Drive/datasets/'\n",
    "file_name = 'heck_512_all/m1559929134.h5'\n",
    "model = K.models.load_model(base_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre running operations\n",
    "# some stat data accumultors for re-running model\n",
    "from time import time\n",
    "epochs_elapsed = 0\n",
    "minutes_elapsed = 0\n",
    "gen = data_gen(BATCH_SIZE, seq_len=(20, MAX_WINDOW_SIZE), track_count=100)\n",
    "test_gen = data_gen(BATCH_SIZE, seq_len=(20, MAX_WINDOW_SIZE), track_count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "STEPS_PER_EPOCH = 1000\n",
    "start_time = time()\n",
    "\n",
    "model.fit_generator(\n",
    "    gen, \n",
    "    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "    epochs=EPOCHS, \n",
    "    validation_data=test_gen, \n",
    "    validation_steps=100,\n",
    "    callbacks=[CustomCallback(600, 16)]\n",
    ")\n",
    "\n",
    "minutes_elapsed += (time() - start_time) // 60\n",
    "epochs_elapsed += EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing/plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(seq_length, batch_size=1, window_len=MAX_WINDOW_SIZE):\n",
    "    # sequence shape is [batch_size, sequence_length, input_size]\n",
    "#     seed = np.zeros((batch_size, 1, INPUT_SIZE)) \n",
    "    seed = np.random.random((batch_size, MAX_WINDOW_SIZE, INPUT_SIZE)) * 0.5\n",
    "    x = seed\n",
    "    accum = [seed]\n",
    "    for i in range(seq_length):\n",
    "        print(i, end=',')\n",
    "        res = model.predict(x).round()\n",
    "        if TARGET_IS_SEQUENCE:\n",
    "            # next input consists of first old input first frame\n",
    "            # and whole result sequence\n",
    "            # (then limited to window size)\n",
    "            x = np.concatenate([x, res[:, -1:, :]], axis=1)[:, -MAX_WINDOW_SIZE:, :]\n",
    "            accum.append(res[:, -1:, :])\n",
    "        else:\n",
    "            # next input consists of previous input\n",
    "            # with result frame attatched to end\n",
    "            # (then limited to window size)\n",
    "            x = np.concatenate([x, res[:, np.newaxis, :]], axis=1)[:, -MAX_WINDOW_SIZE:, :]\n",
    "            accum.append(res[:, np.newaxis, :])\n",
    "    return np.concatenate(accum, axis=1).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def generate_plot(length=300, batch_size=16):\n",
    "    x = generate(length, batch_size)\n",
    "    fig, axs = plt.subplots(nrows=4, ncols=4, figsize=(30, 10),\n",
    "                            subplot_kw={'xticks': [], 'yticks': []})\n",
    "    for ax, x_ in zip(axs.flat, x):\n",
    "        ax.imshow(x_.T[::-1, :])\n",
    "    plt.tight_layout()\n",
    "    res = plt.gcf()\n",
    "    plt.show()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapping it up in callback\n",
    "import json\n",
    "from time import time\n",
    "\n",
    "def default(val):\n",
    "    if isinstance(val, np.float32):\n",
    "        return float(val)\n",
    "    raise TypeError\n",
    "\n",
    "class CustomCallback(K.callbacks.Callback):\n",
    "    def __init__(self, plot_length, batch_size, file_path=''):\n",
    "        super().__init__()\n",
    "        self.plot_length = plot_length\n",
    "        self.batch_size = batch_size\n",
    "        self.output = file_path != ''\n",
    "        self.file_path = file_path\n",
    "        self.log = ''\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        plot = generate_plot(self.plot_length, self.batch_size)\n",
    "        if self.output:\n",
    "            t = int(time())\n",
    "            plot.savefig(self.file_path + f'{t}.png')\n",
    "            K.models.save_model(model, self.file_path + f'm{t}.h5')\n",
    "            with open(self.file_path + 'log.txt', 'a+') as fo:\n",
    "                fo.write(self.log)\n",
    "                self.log = ''\n",
    "        self.log += json.dumps(logs, default=default) + '\\n'\n",
    "        return\n",
    "      \n",
    "    def on_train_end(self, logs={}):\n",
    "        if not self.output:\n",
    "            return\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/content/drive/My Drive/datasets/'\n",
    "keywords = '_'.join(['beth', 'notransp', 'randchunk'])\n",
    "file_name = f'{keywords}_{HIDDEN_SIZE}_{epochs_elapsed}epochs_{minutes_elapsed}m.h5'\n",
    "\n",
    "K.models.save_model(model, base_path + file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
